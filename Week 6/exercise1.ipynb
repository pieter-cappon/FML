{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('simpsons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_character_text</th>\n      <th>spoken_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Miss Hoover</td>\n      <td>No, actually, it was a little of both. Sometim...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lisa Simpson</td>\n      <td>Where's Mr. Bergstrom?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Miss Hoover</td>\n      <td>I don't know. Although I'd sure like to talk t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lisa Simpson</td>\n      <td>That life is worth living.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Edna Krabappel-Flanders</td>\n      <td>The polls will be open from now until the end ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        raw_character_text                                       spoken_words\n0              Miss Hoover  No, actually, it was a little of both. Sometim...\n1             Lisa Simpson                             Where's Mr. Bergstrom?\n2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n3             Lisa Simpson                         That life is worth living.\n4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_character_text</th>\n      <th>spoken_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Lisa Simpson</td>\n      <td>Where's Mr. Bergstrom?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lisa Simpson</td>\n      <td>That life is worth living.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Bart Simpson</td>\n      <td>Victory party under the slide!</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Lisa Simpson</td>\n      <td>Mr. Bergstrom! Mr. Bergstrom!</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Lisa Simpson</td>\n      <td>Do you know where I could find him?</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   raw_character_text                         spoken_words\n1        Lisa Simpson               Where's Mr. Bergstrom?\n3        Lisa Simpson           That life is worth living.\n7        Bart Simpson       Victory party under the slide!\n9        Lisa Simpson        Mr. Bergstrom! Mr. Bergstrom!\n11       Lisa Simpson  Do you know where I could find him?"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df['raw_character_text'].isin(['Lisa Simpson', 'Bart Simpson'])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "There are 14258 words in the vocabulary. A selection: ['anguished', 'angus', 'anima', 'animal', 'animals', 'animated', 'animation', 'animators', 'anka', 'ankle', 'ann', 'annapolis', 'anne', 'annie', 'anniversary', 'annnnd', 'announce', 'announcement', 'announcements', 'announcer']\n"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #The CountVectorizer object\n",
    " \n",
    "text = df['spoken_words'].values.astype('U') #Taking the text from the df. We need to convert it to Unicode\n",
    "\n",
    "vect = CountVectorizer(stop_words='english') #Create the CV object, with English stop words\n",
    "vect = vect.fit(text) #We fit the model with the words from the review text\n",
    "vect\n",
    "feature_names = vect.get_feature_names() #Get the words from the vocabulary\n",
    "print(f\"There are {len(feature_names)} words in the vocabulary. A selection: {feature_names[500:520]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(24, 424)\t1\n  (40, 325)\t1\n  (45, 266)\t1\n  (63, 269)\t1\n  (74, 356)\t1\n  (80, 264)\t1\n  (82, 304)\t1\n  (98, 192)\t1\n  (100, 396)\t1\n  (151, 328)\t1\n  (156, 325)\t1\n  (157, 451)\t1\n  (163, 325)\t1\n  (164, 325)\t1\n  (186, 461)\t1\n  (207, 325)\t1\n  (210, 397)\t1\n  (231, 270)\t1\n  (237, 404)\t1\n  (259, 325)\t1\n  (287, 325)\t1\n  (294, 493)\t1\n  (295, 163)\t1\n  (318, 300)\t1\n  (321, 281)\t1\n  (356, 450)\t1\n  (358, 397)\t1\n  (362, 449)\t1\n  (366, 24)\t1\n  (366, 449)\t1\n  (386, 129)\t1\n  (387, 325)\t1\n  (388, 70)\t1\n  (394, 38)\t1\n  (394, 91)\t1\n  (396, 446)\t1\n  (398, 126)\t1\n  (410, 52)\t1\n  (410, 319)\t1\n  (410, 343)\t1\n  (413, 449)\t1\n  (419, 196)\t1\n  (428, 360)\t1\n  (464, 304)\t1\n"
    }
   ],
   "source": [
    "docu_feat = vect.transform(text) #The transform method from the CountVectorizer object creates the matrix\n",
    "print(docu_feat[0:500,0:500]) #Let's print a little part of the matrix: the first 50 words & documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_character_text</th>\n      <th>spoken_words</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>14248</th>\n      <th>14249</th>\n      <th>14250</th>\n      <th>14251</th>\n      <th>14252</th>\n      <th>14253</th>\n      <th>14254</th>\n      <th>14255</th>\n      <th>14256</th>\n      <th>14257</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 14260 columns</p>\n</div>",
      "text/plain": "  raw_character_text spoken_words    0    1    2    3    4    5    6    7  \\\n0                NaN          NaN  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n\n   ...  14248  14249  14250  14251  14252  14253  14254  14255  14256  14257  \n0  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n\n[1 rows x 14260 columns]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a regular matrix out of docu_feat, make it into a DataFrame and concatenate it along the columns\n",
    "rev_words = pd.concat([df, pd.DataFrame(docu_feat.toarray())], axis=1)\n",
    "rev_words.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v_raw_character_text</th>\n      <th>v_spoken_words</th>\n      <th>000</th>\n      <th>007</th>\n      <th>10</th>\n      <th>1000</th>\n      <th>10201</th>\n      <th>108</th>\n      <th>1094</th>\n      <th>11</th>\n      <th>...</th>\n      <th>zork</th>\n      <th>zorrinid</th>\n      <th>zuckerberg</th>\n      <th>zuh</th>\n      <th>zumanity</th>\n      <th>zur</th>\n      <th>zz</th>\n      <th>zzzapp</th>\n      <th>ãªtre</th>\n      <th>ãºna</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lisa Simpson</td>\n      <td>Where's Mr. Bergstrom?</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lisa Simpson</td>\n      <td>That life is worth living.</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 14260 columns</p>\n</div>",
      "text/plain": "  v_raw_character_text              v_spoken_words  000  007   10  1000  \\\n0                  NaN                         NaN  0.0  0.0  0.0   0.0   \n1         Lisa Simpson      Where's Mr. Bergstrom?  0.0  0.0  0.0   0.0   \n2                  NaN                         NaN  0.0  0.0  0.0   0.0   \n3         Lisa Simpson  That life is worth living.  0.0  0.0  0.0   0.0   \n4                  NaN                         NaN  0.0  0.0  0.0   0.0   \n\n   10201  108  1094   11  ...  zork  zorrinid  zuckerberg  zuh  zumanity  zur  \\\n0    0.0  0.0   0.0  0.0  ...   0.0       0.0         0.0  0.0       0.0  0.0   \n1    0.0  0.0   0.0  0.0  ...   0.0       0.0         0.0  0.0       0.0  0.0   \n2    0.0  0.0   0.0  0.0  ...   0.0       0.0         0.0  0.0       0.0  0.0   \n3    0.0  0.0   0.0  0.0  ...   0.0       0.0         0.0  0.0       0.0  0.0   \n4    0.0  0.0   0.0  0.0  ...   0.0       0.0         0.0  0.0       0.0  0.0   \n\n    zz  zzzapp  ãªtre  ãºna  \n0  0.0     0.0    0.0   0.0  \n1  0.0     0.0    0.0   0.0  \n2  0.0     0.0    0.0   0.0  \n3  0.0     0.0    0.0   0.0  \n4  0.0     0.0    0.0   0.0  \n\n[5 rows x 14260 columns]"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Relabeling the columns. feature_names contains the words in the text. I've used the v (variable) + underscore to distinguish from the words like 'hotel' in the text\n",
    "#Hard-coding the names like this is not really good practice (better would be some operation on the dataframe), but it's a lot clearer.\n",
    "\n",
    "rev_words.columns = ['v_raw_character_text', 'v_spoken_words'] + feature_names\n",
    "rev_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.6365676567656766"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Setting up the data and model\n",
    "nb = MultinomialNB()\n",
    "X = docu_feat #selecting the variables to go into my X matrix\n",
    "y = df['raw_character_text'] #creating the y vector\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) #split the data and store it\n",
    "\n",
    "nb = nb.fit(X_train, y_train)\n",
    "nb.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Bart Simpson    0.544954\nLisa Simpson    0.455046\nName: raw_character_text, dtype: float64"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['raw_character_text'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3261,  820],\n       [1933, 1561]], dtype=int64)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_test_pred = nb.predict(X_test) #the predicted values\n",
    "cm = confusion_matrix(y_test, y_test_pred) #creates a \"confusion matrix\"\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Bart_p</th>\n      <th>Lisa_p</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Bart</th>\n      <td>3261</td>\n      <td>820</td>\n    </tr>\n    <tr>\n      <th>Lisa</th>\n      <td>1933</td>\n      <td>1561</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      Bart_p  Lisa_p\nBart    3261     820\nLisa    1933    1561"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In order to read it easily , let's make a dataframe out of it, and add labels to it.\n",
    "conf_matrix = pd.DataFrame(cm, index=['Bart', 'Lisa'], columns = ['Bart_p', 'Lisa_p']) \n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "precision    recall  f1-score   support\n\nBart Simpson       0.63      0.80      0.70      4081\nLisa Simpson       0.66      0.45      0.53      3494\n\n   micro avg       0.64      0.64      0.64      7575\n   macro avg       0.64      0.62      0.62      7575\nweighted avg       0.64      0.64      0.62      7575\n\n"
    }
   ],
   "source": [
    "# calculating accuracy, recall and precision\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.02580694, 0.97419306]])"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict_proba(X[:1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "sentence 1 That life is worth living.\n[[0.69449341 0.30550659]]\nsentence 2 Victory party under the slide!\n[[0.76243062 0.23756938]]\nsentence 3 Mr. Bergstrom! Mr. Bergstrom!\n[[4.27957359e-04 9.99572043e-01]]\nsentence 4 Do you know where I could find him?\n[[0.55340771 0.44659229]]\nsentence 5 The train, how like him... traditional, yet environmentally sound.\n[[0.02857325 0.97142675]]\nsentence 6 I see he touched you, too.\n[[0.52425227 0.47574773]]\nsentence 7 Hey, thanks for your vote, man.\n[[0.9501968 0.0498032]]\nsentence 8 Well, you got that right. Thanks for your vote, girls.\n[[0.78929503 0.21070497]]\nsentence 9 Well, don't sweat it. Just so long as a couple of people did... right, Milhouse?\n[[0.58792341 0.41207659]]\nsentence 10 Lewis?\n[[0.81508251 0.18491749]]\nsentence 11 Somebody must have voted.\n[[0.35143517 0.64856483]]\nsentence 12 Uh oh.\n[[0.71282318 0.28717682]]\nsentence 13 nan\n[[0.52988561 0.47011439]]\nsentence 14 I demand a recount.\n[[0.85777683 0.14222317]]\nsentence 15 No.\n[[0.54710575 0.45289425]]\nsentence 16 Mr. Bergstrom! Hey, Mr. Bergstrom!\n[[0.00127793 0.99872207]]\nsentence 17 Hey, Lisa, indeed.\n[[0.91424801 0.08575199]]\nsentence 18 Oh, I mean, were you just going to leave, just like that?\n[[0.57529072 0.42470928]]\nsentence 19 You can't go! You're the best teacher I'll ever have.\n[[0.63106055 0.36893945]]\nsentence 20 Oh, please.\n[[0.57636925 0.42363075]]\nsentence 21 But I need you too.\n[[0.59569816 0.40430184]]\nsentence 22 I, I understand. Mr. Bergstrom, I'm going to miss you.\n[[0.00877343 0.99122657]]\nsentence 23 Thank you, Mr. Bergstrom.\n[[0.01229415 0.98770585]]\nsentence 24 So, I guess this is it? It you don't mind I'll just run alongside the train as it speeds you from my life?\n[[0.04688661 0.95311339]]\nsentence 25 Nothing.\n[[0.54710575 0.45289425]]\nsentence 26 Mr. Bergstrom left today.\n[[0.02303214 0.97696786]]\nsentence 27 He's gone. Forever.\n[[0.64001658 0.35998342]]\n"
    }
   ],
   "source": [
    "for i in range(1, 28):\n",
    "    print('sentence', i, df.spoken_words.iloc[i])\n",
    "    print(clf.predict_proba(X[i]))\n",
    "    \n",
    "    i+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}